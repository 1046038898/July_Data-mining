{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "适用于面对海量数据进行关键索引，不要硬碰硬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN(最近邻-只根据一个点predcit结果)缺点：如果数据中存在噪声，那么会对预测数据产生巨大影响（比如根据异常数据恰好predict了一个错误的结果）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN(根据多个点predict结果，准确性更高，而且还可以降低噪声点带来的影响)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如你你想要判断一个人的生活状况、社会地位、财富收入等信息，可以观察与他关系较好的K个朋友的信息，大概就可以得出conclusion。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**要建立索引-加快速度（要先对数据进行划分）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSH的直观理解：会有一部分精度损失\n",
    "\n",
    "那么如何提高精度呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSH之相似网页查找**\n",
    "\n",
    "Google的做法：先把doc文档进行分词，比如：美国51区雇员称内部有9架飞碟，曾看见灰色外星人。先进行分词，因为谷歌把词语压缩成64bit，所以通过hash进行压缩之后，有6个字符，我们预先计算出每个词语所对应的权重，如果哈希对应的是1，则乘以权重的值，如果哈希对应的是0，则乘以权重的值的负数。这样每个词语都计算出对应的值，然后把每一列进行相加，得出一个值。如果大于0则返回1，如果小于0则返回0.这是第一个文档的结果\n",
    "\n",
    "同理我们要计算网页之间的相似度，如果第二个文档的值和第一个文档的值相差不大，则表示这两个网页相似度很高，需要去重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lshash**\n",
    "\n",
    "初始索引是8，建立完成之后索引是6\n",
    "\n",
    "缺点：保证不了准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最近邻问题(NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "猜猜看：最后一行未知电影属于什么类型的电影"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_film.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据NN算法，我们只需要在上述坐标中找出离目标点最近的点，然后将目标点的电影类型等价于离它最近点的电影类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K最近邻算法（NN=>KNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图中绿色的圆点X是什么形状?\n",
    "\n",
    "**依据周边最“近”K个点的类别共同判定**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_graph.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如，我们设定K=4，找出与目标值最近的四个图形，判断哪种图形占比最多，那么目标值就属于那种图形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 距离准则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**相似度/距离定义**\n",
    "\n",
    "* **欧氏距离**\n",
    "$$\n",
    "\\operatorname{dist}(X, Y)=\\left(\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|^{p}\\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "* **Jaccard（杰卡德）相似度**：主要用来计算样本间的相似度。\n",
    "\n",
    " 计算方式：样本交集个数和样本并集个数的比值。\n",
    " \n",
    " 例子：集合A = {a, b, c, d} ,集合B = {c, d, e, f} ,A∩B = {c, d} A∪B = {a, b, c, d, e, f} \n",
    " 交集中有2个元素，并集中有6个元素，因此：J(A,B) = 2/6 = 1/3 \n",
    " \n",
    "$$\n",
    "J(A, B)=\\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "* **余弦相似度**：是通过计算两个向量的夹角余弦值来评估他们之间的相似度。两个向量之间的角度是0，那么余弦相似度是1；两个向量之间的角度是180，那么余弦相似度是-1.余弦相似度值的区间[-1,1]\n",
    "\n",
    "$$\n",
    "\\cos (\\theta)=\\frac{a^{T} b}{|a| \\cdot|b|}\n",
    "$$\n",
    "* **Pearson相似度**:是用来衡量两个数据集合是否在一条线上面，它用来衡量定距变量间的线性关系。如衡量身高和体重、高中成绩和高考成绩等变量之间的线性关系。相关系数的绝对值越大，相关性越强；相关系数越接近于1或-1，相关度越强，相关系数越接近于0，相关度越弱。\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\mu_{X}\\right)\\left(Y_{i}-\\mu_{Y}\\right)}{\\sqrt{\\sum_{i=1}^{n}\\left(X_{i}-\\mu_{X}\\right)^{2}} \\sqrt{\\sum_{i=1}^{n}\\left(Y_{i}-\\mu_{Y}\\right)^{2}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 近似最近邻问题（KNN=>ANN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Google/Baidu 每天有海量的网页，怎么判断内容是否和之前的网页相近？\n",
    "* 论文查重的时候如何快速定位是否剽窃？\n",
    "* 推荐的时候，如何快速找到接近的用户/商品？\n",
    "* 图像检索的时候，如何比对海量图片找相近？\n",
    "* 指纹匹配\n",
    "\n",
    "* 在高维空间，线性比对效率太太太低…\n",
    "* 我们需要**近似最近邻（ANN）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 近似最近邻算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不管何种算法，都是尽量**预先对数据做一些划分和索引**。\n",
    "\n",
    "损失了一点点准确率，换取搜索速度的极大提升。\n",
    "\n",
    "工程上常用算法：\n",
    "* LSH（Local Sensitive Hash/局部敏感度哈希）\n",
    "* K-Means Tree\n",
    "* K-D Tree\n",
    "\n",
    "说明：\n",
    "* ANN的算法帮助我们缩小范围和提速，严格的距离排序依旧需要依托于前面的距离准则。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部敏感度哈希"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通hash避开碰撞。\n",
    "* 在一般的哈希表中，我们先建立一个空的哈希表，然后根据算法，将每个不同的数据填充进表中，避免碰撞。\n",
    "\n",
    "\n",
    "\n",
    "LSH保证高维空间相近的点在低维空间相近的概率很高\n",
    "* 也就是说通过映射之后，低纬度空间里点之间的分布大部分和没有映射之前高纬度空间里的点分布情况相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_hash.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成2进制串，保证距离特性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_chuan.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从原数据中我们可以看出目标是寻找与老虎相似的图像。我们这里假设数据的shape[0]=10000,我们生成六个2进制串，也就是一共会有32中不同的情况，这样我们就会把10000张图片根据算法，计算相似性，把他们分别落入不同的桶里面（每个不同的2进制串作为一个桶），这样我们就可以找到与源图片相似度最高的图片，然后我们比对桶中与其最相似的图片，成功找出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH的直观理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 把原始的样本点映射成长度为N的一个2进制串\n",
    "* 其中每个位次可以理解为在空间取了一个超平面去做划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_kong.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们划分超平面。如左边图所示，我们划分为蓝红绿三种不同颜色的超平面。一共有8种情况。比如我们要找出与a相似的两个点。\n",
    "\n",
    "我们先对a进行判断，首先a出在蓝色超平面下方，所以为1，处在红色超平面上方，所以为0，处在绿色超平面下方，所以为0.以此类推，计算出abd属于相似的一类，我们对右图重新进行超平面划分，得出不同的与a相似的点为ace。那么接下来如何判断哪两个点与a点最相似呢？我们求其并集{b,c,d,e}在并集中计算和a最近的两个点，这部分计算资源开销不大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH之相似网页查找"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "寻找相近的网页问题：如何快速判断哪些网页非常相近呢？\n",
    "\n",
    "**常用的网页文本比对处理方法**\n",
    "\n",
    "* 分词后Jaccard相似度或者编辑距离\n",
    "\n",
    "  缺点：比对很慢\n",
    "  \n",
    "* 百度前期的实现方式\n",
    "  \n",
    "  找出Top N长度的句子，直接hash成N个签名。简单粗暴，准确率/召回率 大概在80%(猜测是国人喜欢复制粘贴)\n",
    " \n",
    "* Shingle算法\n",
    "\n",
    "  原理略复杂，学术派，有兴趣看http://nlp.stanford.edu/IR-book/html/htmledition/near-duplicates-and-shingling-1.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH之相似网页查找"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "汉明距离：表示两个（相同长度）子对应位不同的数量\n",
    "\n",
    "例如：1011101与1001001，有两个对应位不同，那么汉明长度就是2\n",
    "\n",
    "**Simhash：Google每天用它完成亿级别的网页去重，汉明距离<=3**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_simhash.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_mei.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google的做法：先把doc文档进行分词，比如：美国51区雇员称内部有9架飞碟，曾看见灰色外星人。先进行分词，因为谷歌把词语压缩成64bit，所以通过hash进行压缩之后，有6个字符，我们预先计算出每个词语所对应的权重，如果哈希对应的是1，则乘以权重的值，如果哈希对应的是0，则乘以权重的值的负数。这样每个词语都计算出对应的值，然后把每一列进行相加，得出一个值。如果大于0则返回1，如果小于0则返回0.这是第一个文档的结果\n",
    "\n",
    "同理我们要计算网页之间的相似度，如果第二个文档的值和第一个文档的值相差的汉明距离小于3，则表示这两个网页相似度很高，需要去重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimHash可用库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 针对中文网页的C++版simhash：https://github.com/yanyiwu/simhash\n",
    "* Python版simhash：https://github.com/leonsim/simhash\n",
    "* 请使用jieba等python分词工具对中文预先处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH常用库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本之外的其他格式的数据，如何求近似最近邻？\n",
    "\n",
    "* **先把数据表示成向量格式**\n",
    "\n",
    "  1.文本：bag of words，ti-idf\n",
    "  \n",
    "  2.图像：GIST，HOG，SIFT，或者卷积神经网络尾层（现在经常用的是卷积神经网络尾层）\n",
    "  \n",
    "  3.用户数据：交互的商品和用户行为的统计值向量\n",
    "  \n",
    "* **使用库完成向量向低维度2进制空间映射，关键在于找到合适的“超平面”切分得到01**\n",
    "\n",
    "  1.MIT的E2LSH包：http://www.mit.edu/~andoni/LSH/\n",
    "  \n",
    "  2.Python的最简单实现：https://github.com/kayzh/LSHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN之K-means Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-means是大家都熟知的聚类算法。\n",
    "* **K-means Tree实际就是对数据做了多层K-means**\n",
    "* 每一层到当前的划分\"叶子节点\"包含样本数都少于T个结束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_kmens_tree.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_tree.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means tree的算法流程：我们先用多层K-Means算法进行套用，知道计算出树的叶子节点中满足样本数小于等于我们给定的阈值T。\n",
    "\n",
    "我们来看这棵树。假定我们我们需要找到T/2个样本与给定目标值相似的样本，从上往下看，我们假设第二个聚类中心离木标值最近，这时候再从第二类样本继续往下找，发现第三层第一个聚类中心离目标值最近，假设第三层第一个聚类中心中的样本数量是T+1，我们接着往下继续找，发现第四层第一个聚类中心离目标值最近，且其中样本个数为T/2+1,大于T/2个样本，那么从T/2+1个样本中找出离目标值最相似的T/2个样本；如果样本数小于T/2，则往上回溯，到了第三层第二个聚类中心，因为之前提到过其样本数量为T+1，满足条件，那么从中选择T/2个与目标值最相似的样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN之K-D Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-dimension tree，对数据点在k维空间中划分的一种数据结构。\n",
    "* **K-D tree实际上是一种二叉树**。\n",
    "* 简单说一下构建和检索近似最近邻过程。\n",
    "  * {(2,3),(5,4),(9,6),(4,7), (8,1), (7,2)} 6个样本点\n",
    "  *  找波动/方差最大的维度做二叉树切分--不确定性信息增益和熵比较高（减小不确定的可能性最大）\n",
    "  * 递归地完成这个过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_d_tree.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立这棵树：从数据中可以看出，有X和Y两个维度，哪个维度波动最大？X{7,8,4,9,5,2}，Y{2,1,7,6,4,3}可以看出X轴波动较大，所以从X里面选择中位数7作为起始节点，然后均匀分配，524分到左边，98分到右边。Y中数据也以此类推。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建树过程直观理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_d_tree2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中可以看出先将起始节点(7,2)处划分出一条，然后左边节点和右边节点分别画出一条。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_3_dim.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二维的时候以线划分，三维的时候就以面划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据是N维？\n",
    "* 会取数据的Top M个波动/方差最大的维度切分\n",
    "* 有时候会随机取样本来确定哪些维度波动高，从而建立多棵树\n",
    "\n",
    "怎么找Top N近似最近邻？\n",
    "* 先通过二叉树找到最近邻\n",
    "* 回溯找到可能的Top K近似最近邻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Tree VS K-D Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间复杂度对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_contrast.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工程经验之ANN库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANNOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C++实现，有python接口，有R/scala/Java/Lua/go版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='722_annoy.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建索引与最近邻查找，可以直接用list作为向量输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'annoy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-383358162bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mannoy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnnoyIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'annoy'"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
